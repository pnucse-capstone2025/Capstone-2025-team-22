import torch
import sys
import os
import logging
from torch.utils.data import DataLoader

# ë¶€ëª¨ ë””ë ‰í† ë¦¬ ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
grandparent_dir = os.path.dirname(parent_dir)
sys.path.insert(0, grandparent_dir)

# test.pyì—ì„œ import
from ...src.data.dataset import load_data, KeywordDataset, Collator
from ...src.models.kokeybert import KoKeyBERT
from test import test, extract_keywords_from_bio_tags, evaluate_keywords
from transformers import BertConfig

def test_kokeybert_performance():
    """test.pyì™€ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ KoKeyBERT ì„±ëŠ¥ ì¸¡ì •"""
    print("ğŸ¯ KoKeyBERT ì„±ëŠ¥ ì¸¡ì • (test.py ë°©ì‹)")
    
    # ë¡œê±° ì„¤ì •
    logger = logging.getLogger("kokeybert_test")
    logger.setLevel(logging.INFO)
    
    # í•¸ë“¤ëŸ¬ ì œê±° (ì¤‘ë³µ ë°©ì§€)
    if logger.handlers:
        logger.handlers.clear()
    
    # ìŠ¤íŠ¸ë¦¼ í•¸ë“¤ëŸ¬
    stream_handler = logging.StreamHandler()
    stream_handler.setLevel(logging.INFO)
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    stream_handler.setFormatter(formatter)
    logger.addHandler(stream_handler)
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ”§ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
    
    try:
        # 1. test.pyì™€ ë™ì¼í•œ ë°ì´í„° ë¡œë“œ
        print("ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”© ì¤‘...")
        test_data_path = "../../src/data/test_clean.json"
        
        if not os.path.exists(test_data_path):
            print(f"âŒ ë°ì´í„° íŒŒì¼ ì—†ìŒ: {test_data_path}")
            # ëŒ€ì•ˆ ê²½ë¡œë“¤ ì‹œë„
            alternative_paths = [
                "../../../src/data/test_clean.json",
                "../../data/test_clean.json", 
                "../data/test_clean.json",
                "./test_clean.json"
            ]
            
            for alt_path in alternative_paths:
                if os.path.exists(alt_path):
                    test_data_path = alt_path
                    print(f"âœ… ëŒ€ì•ˆ ê²½ë¡œ ë°œê²¬: {test_data_path}")
                    break
            else:
                print("âŒ ëª¨ë“  ëŒ€ì•ˆ ê²½ë¡œì—ì„œ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return
        
        test_data = load_data(test_data_path)
        if test_data is None or len(test_data) == 0:
            raise ValueError(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ ë˜ëŠ” ë¹„ì–´ìˆìŒ: {test_data_path}")
        
        print(f"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ: {len(test_data)} í•­ëª©")
        test_dataset = KeywordDataset(test_data)
        
        # 2. í† í¬ë‚˜ì´ì € ì´ˆê¸°í™”
        print("ğŸ”¤ í† í¬ë‚˜ì´ì € ë¡œë”© ì¤‘...")
        try:
            sys.path.append('../../kobert_tokenizer')
            from ....tokenizer.kobert_tokenizer import KoBERTTokenizer
            tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')
            collator = Collator(tokenizer)
            print("âœ… KoBERT í† í¬ë‚˜ì´ì € ë¡œë“œ ì„±ê³µ")
        except Exception as e:
            print(f"âš ï¸ KoBERT í† í¬ë‚˜ì´ì € ë¡œë“œ ì‹¤íŒ¨: {e}")
            return
        
        # 3. ëª¨ë¸ ë¡œë“œ
        print("ğŸ—ï¸ KoKeyBERT ëª¨ë¸ ë¡œë”© ì¤‘...")
        model_name = "skt/kobert-base-v1"
        checkpoint_path = "../../checkpoints/best_model.pt"
        
        if not os.path.exists(checkpoint_path):
            print(f"âŒ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì—†ìŒ: {checkpoint_path}")
            # ëŒ€ì•ˆ ê²½ë¡œë“¤ ì‹œë„
            alternative_checkpoints = [
                "../../../checkpoints/best_model.pt",
                "../../best_model.pt",
                "../best_model.pt",
                "./best_model.pt"
            ]
            
            for alt_path in alternative_checkpoints:
                if os.path.exists(alt_path):
                    checkpoint_path = alt_path
                    print(f"âœ… ëŒ€ì•ˆ ì²´í¬í¬ì¸íŠ¸ ë°œê²¬: {checkpoint_path}")
                    break
            else:
                print("âŒ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return
        
        try:
            config = BertConfig.from_pretrained(model_name)
            model = KoKeyBERT(config=config)
            model.load_state_dict(torch.load(checkpoint_path, map_location=device))
            model.to(device)
            print("âœ… KoKeyBERT ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì˜¤ë¥˜: {e}")
            return
        
        # 4. í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (test.pyì™€ ë™ì¼í•œ ë°©ì‹)
        print("\nğŸš€ KoKeyBERT í…ŒìŠ¤íŠ¸ ì‹œì‘!")
        print("="*50)
        
        # ê°€ì§œ args ê°ì²´ ìƒì„±
        class Args:
            def __init__(self):
                self.batch_size = 8
                self.num_workers = 0  # multiprocessing ë¬¸ì œ ë°©ì§€
                self.log_freq = 10
                self.save_results = False
        
        args = Args()
        
        # test í•¨ìˆ˜ ì‹¤í–‰
        kokeybert_loss, kokeybert_acc, kokeybert_precision, kokeybert_recall, kokeybert_f1 = test(
            model=model,
            test_dataset=test_dataset,
            collator=collator,
            args=args,
            logger=logger,
            device=device
        )
        
        print("\n" + "="*50)
        print("ğŸ‰ KoKeyBERT í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("="*50)
        print(f"ğŸ“Š ìµœì¢… ê²°ê³¼:")
        print(f"   ì†ì‹¤: {kokeybert_loss:.4f}")
        print(f"   ì •í™•ë„: {kokeybert_acc:.4f}")
        print(f"   ì •ë°€ë„: {kokeybert_precision:.4f}")
        print(f"   ì¬í˜„ìœ¨: {kokeybert_recall:.4f}")
        print(f"   F1 ì ìˆ˜: {kokeybert_f1:.4f}")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_kokeybert_performance()
